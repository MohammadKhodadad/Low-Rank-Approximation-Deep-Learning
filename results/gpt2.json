{"name": "gpt2", "model_size": 486814090, "trainable_params": 124439808, "all_params": 124439808, "cpu_inference_time": 1.520178840495646, "gpu_inference_time": 0.01406070007942617, "base_perplexity": 40.20892066964827, "training_time": 0.6747210755526463, "history": [{"epoch": 0, "train_loss": 3.67312921430463, "test_perplexity": 32.50099698121457}, {"epoch": 1, "train_loss": 3.554832191667824, "test_perplexity": 31.08646803493892}, {"epoch": 2, "train_loss": 3.5042228459197786, "test_perplexity": 30.302736696491777}, {"epoch": 3, "train_loss": 3.4679044930734366, "test_perplexity": 29.737879189847824}, {"epoch": 4, "train_loss": 3.438475532509456, "test_perplexity": 29.276891218991555}, {"epoch": 5, "train_loss": 3.4124301276474354, "test_perplexity": 28.89147654338251}, {"epoch": 6, "train_loss": 3.389649419026954, "test_perplexity": 28.5814550696461}, {"epoch": 7, "train_loss": 3.368655359076562, "test_perplexity": 28.270301622728773}, {"epoch": 8, "train_loss": 3.349513635457119, "test_perplexity": 28.029082170124457}, {"epoch": 9, "train_loss": 3.331007419345535, "test_perplexity": 27.84790296840057}, {"epoch": 10, "train_loss": 3.313012273512154, "test_perplexity": 27.579466692487767}, {"epoch": 11, "train_loss": 3.298204472131818, "test_perplexity": 27.435798156139583}, {"epoch": 12, "train_loss": 3.282756118016822, "test_perplexity": 27.28141821401696}, {"epoch": 13, "train_loss": 3.267270703739095, "test_perplexity": 27.145366851109454}, {"epoch": 14, "train_loss": 3.252392005697589, "test_perplexity": 27.003068323931934}, {"epoch": 15, "train_loss": 3.239085445894259, "test_perplexity": 26.85733647664404}, {"epoch": 16, "train_loss": 3.226691134622164, "test_perplexity": 26.792489033229636}, {"epoch": 17, "train_loss": 3.2136209328597953, "test_perplexity": 26.651586359295795}, {"epoch": 18, "train_loss": 3.200864233703257, "test_perplexity": 26.54963292068298}, {"epoch": 19, "train_loss": 3.1889238931308284, "test_perplexity": 26.46922318380439}, {"epoch": 20, "train_loss": 3.1774752296019937, "test_perplexity": 26.40535836725191}, {"epoch": 21, "train_loss": 3.166330576500046, "test_perplexity": 26.358964343181018}, {"epoch": 22, "train_loss": 3.155008905401854, "test_perplexity": 26.252022216441308}, {"epoch": 23, "train_loss": 3.1435861409267534, "test_perplexity": 26.1928512048921}, {"epoch": 24, "train_loss": 3.131043130549315, "test_perplexity": 26.14377194832654}, {"epoch": 25, "train_loss": 3.1224495562437538, "test_perplexity": 26.074532519611736}, {"epoch": 26, "train_loss": 3.1112000452023802, "test_perplexity": 26.028107780873516}, {"epoch": 27, "train_loss": 3.1013191721149695, "test_perplexity": 26.004890877689455}, {"epoch": 28, "train_loss": 3.091451581393447, "test_perplexity": 25.981071954965955}, {"epoch": 29, "train_loss": 3.0819888337750303, "test_perplexity": 25.935806251450593}, {"epoch": 30, "train_loss": 3.071422222061692, "test_perplexity": 25.918808631890563}, {"epoch": 31, "train_loss": 3.061921652232375, "test_perplexity": 25.891873946661654}, {"epoch": 32, "train_loss": 3.053092417872955, "test_perplexity": 25.803273561490546}, {"epoch": 33, "train_loss": 3.043375831898128, "test_perplexity": 25.828520210203152}, {"epoch": 34, "train_loss": 3.0348219425878793, "test_perplexity": 25.820417165626427}, {"epoch": 35, "train_loss": 3.0256342325255137, "test_perplexity": 25.81166401179225}, {"epoch": 36, "train_loss": 3.016507368221461, "test_perplexity": 25.78986334835582}, {"epoch": 37, "train_loss": 3.0070584187997835, "test_perplexity": 25.7514847112149}, {"epoch": 38, "train_loss": 2.9992295135961515, "test_perplexity": 25.79908009425944}, {"epoch": 39, "train_loss": 2.989875905981688, "test_perplexity": 25.75645505457314}, {"epoch": 40, "train_loss": 2.980626987519665, "test_perplexity": 25.746988413415348}, {"epoch": 41, "train_loss": 2.973618407115758, "test_perplexity": 25.743377742782446}, {"epoch": 42, "train_loss": 2.9646328698808904, "test_perplexity": 25.78509312823014}, {"epoch": 43, "train_loss": 2.954540870457052, "test_perplexity": 25.722928309560725}, {"epoch": 44, "train_loss": 2.947803270593982, "test_perplexity": 25.741630716006764}, {"epoch": 45, "train_loss": 2.9405200849069613, "test_perplexity": 25.77338697096352}, {"epoch": 46, "train_loss": 2.9325811144347504, "test_perplexity": 25.844733234867302}, {"epoch": 47, "train_loss": 2.9242883831541113, "test_perplexity": 25.784297544005337}, {"epoch": 48, "train_loss": 2.9159304159823978, "test_perplexity": 25.778993578537346}, {"epoch": 49, "train_loss": 2.9086079614184728, "test_perplexity": 25.805357747128973}, {"epoch": 50, "train_loss": 2.899880802519968, "test_perplexity": 25.854610339220777}, {"epoch": 51, "train_loss": 2.892851185575824, "test_perplexity": 25.86201272959049}, {"epoch": 52, "train_loss": 2.8846269595288785, "test_perplexity": 25.877172906647885}, {"epoch": 53, "train_loss": 2.8772422052989497, "test_perplexity": 25.914312415475433}, {"epoch": 54, "train_loss": 2.869606981767672, "test_perplexity": 25.870538455463528}, {"epoch": 55, "train_loss": 2.86263755715896, "test_perplexity": 25.942895248381603}, {"epoch": 56, "train_loss": 2.8544355285501926, "test_perplexity": 25.914152777627613}, {"epoch": 57, "train_loss": 2.847595157467316, "test_perplexity": 25.97443725328628}, {"epoch": 58, "train_loss": 2.8396812020061173, "test_perplexity": 26.059650941096752}, {"epoch": 59, "train_loss": 2.8318193254069746, "test_perplexity": 26.02768377583415}, {"epoch": 60, "train_loss": 2.8253770465048675, "test_perplexity": 26.061748426354782}, {"epoch": 61, "train_loss": 2.817808419187492, "test_perplexity": 26.17583524688667}, {"epoch": 62, "train_loss": 2.8104676542995133, "test_perplexity": 26.19214877023217}, {"epoch": 63, "train_loss": 2.802863034132485, "test_perplexity": 26.195615079738243}, {"epoch": 64, "train_loss": 2.796078764946661, "test_perplexity": 26.195180333292665}, {"epoch": 65, "train_loss": 2.7890365697513118, "test_perplexity": 26.249273434564582}, {"epoch": 66, "train_loss": 2.781997918525589, "test_perplexity": 26.312753500674294}, {"epoch": 67, "train_loss": 2.775061142778842, "test_perplexity": 26.356959709025194}, {"epoch": 68, "train_loss": 2.7676267607189784, "test_perplexity": 26.344066254034036}, {"epoch": 69, "train_loss": 2.760734298518885, "test_perplexity": 26.389420601809974}, {"epoch": 70, "train_loss": 2.753226690760283, "test_perplexity": 26.43028543877251}, {"epoch": 71, "train_loss": 2.7463728384436847, "test_perplexity": 26.46573973781474}, {"epoch": 72, "train_loss": 2.739855044913069, "test_perplexity": 26.55570963173946}, {"epoch": 73, "train_loss": 2.7332851457818648, "test_perplexity": 26.60124895282804}, {"epoch": 74, "train_loss": 2.7266613400985147, "test_perplexity": 26.671118518513044}, {"epoch": 75, "train_loss": 2.7191810763884927, "test_perplexity": 26.685992667179136}, {"epoch": 76, "train_loss": 2.7124571839225626, "test_perplexity": 26.734066263854384}, {"epoch": 77, "train_loss": 2.7058697097769406, "test_perplexity": 26.79919586262895}, {"epoch": 78, "train_loss": 2.6995789180292147, "test_perplexity": 26.88633183303071}, {"epoch": 79, "train_loss": 2.6924939428534462, "test_perplexity": 26.896563403566574}, {"epoch": 80, "train_loss": 2.685587983822154, "test_perplexity": 26.944741259756128}, {"epoch": 81, "train_loss": 2.6803942105480445, "test_perplexity": 27.03497213446166}, {"epoch": 82, "train_loss": 2.672857299586323, "test_perplexity": 27.120810583293444}, {"epoch": 83, "train_loss": 2.666628505582007, "test_perplexity": 27.225419424853463}, {"epoch": 84, "train_loss": 2.65952825824791, "test_perplexity": 27.203858667292074}, {"epoch": 85, "train_loss": 2.653733934754523, "test_perplexity": 27.255339031137375}, {"epoch": 86, "train_loss": 2.645649466002099, "test_perplexity": 27.25337584837794}, {"epoch": 87, "train_loss": 2.6404403409111166, "test_perplexity": 27.415678162629636}, {"epoch": 88, "train_loss": 2.6339975979840644, "test_perplexity": 27.37798972336839}, {"epoch": 89, "train_loss": 2.6279554628880226, "test_perplexity": 27.51182846649209}, {"epoch": 90, "train_loss": 2.620491539763513, "test_perplexity": 27.51076283009663}, {"epoch": 91, "train_loss": 2.6155014773395573, "test_perplexity": 27.587038503642912}, {"epoch": 92, "train_loss": 2.6087690140599404, "test_perplexity": 27.71932779529625}, {"epoch": 93, "train_loss": 2.602888072762534, "test_perplexity": 27.83381948083908}, {"epoch": 94, "train_loss": 2.595687597154457, "test_perplexity": 27.893932927694387}, {"epoch": 95, "train_loss": 2.5882707650416363, "test_perplexity": 27.933696293930044}, {"epoch": 96, "train_loss": 2.5830068404429425, "test_perplexity": 27.989539378293422}, {"epoch": 97, "train_loss": 2.5770910811201433, "test_perplexity": 28.098266054592504}, {"epoch": 98, "train_loss": 2.570232243181389, "test_perplexity": 28.13432308075936}, {"epoch": 99, "train_loss": 2.5643789634526333, "test_perplexity": 28.186459274391332}, {"epoch": 100, "train_loss": 2.557219507816796, "test_perplexity": 28.21157175041212}, {"epoch": 101, "train_loss": 2.5517976980343042, "test_perplexity": 28.372268750755445}, {"epoch": 102, "train_loss": 2.546543314635197, "test_perplexity": 28.56063078004387}, {"epoch": 103, "train_loss": 2.5403933419245424, "test_perplexity": 28.492829319230108}, {"epoch": 104, "train_loss": 2.534479953975321, "test_perplexity": 28.668625868954617}, {"epoch": 105, "train_loss": 2.5281044612421053, "test_perplexity": 28.705767684734646}, {"epoch": 106, "train_loss": 2.5220421892460263, "test_perplexity": 28.786212333554317}, {"epoch": 107, "train_loss": 2.5157140537957163, "test_perplexity": 28.865304293887405}, {"epoch": 108, "train_loss": 2.510661135210055, "test_perplexity": 29.006090337873278}, {"epoch": 109, "train_loss": 2.5047858056621015, "test_perplexity": 29.047262679834027}, {"epoch": 110, "train_loss": 2.4984713207895513, "test_perplexity": 29.161589955992977}, {"epoch": 111, "train_loss": 2.4918527903957903, "test_perplexity": 29.31385583443916}, {"epoch": 112, "train_loss": 2.4860029081317867, "test_perplexity": 29.31904114712484}, {"epoch": 113, "train_loss": 2.4802934716795093, "test_perplexity": 29.425646617088066}, {"epoch": 114, "train_loss": 2.474501478337796, "test_perplexity": 29.40289508562787}, {"epoch": 115, "train_loss": 2.4682687231313403, "test_perplexity": 29.55419184162533}, {"epoch": 116, "train_loss": 2.4612590436623476, "test_perplexity": 29.545519525634898}, {"epoch": 117, "train_loss": 2.456603378893059, "test_perplexity": 29.79034607220246}, {"epoch": 118, "train_loss": 2.449753731767708, "test_perplexity": 29.831148391446998}, {"epoch": 119, "train_loss": 2.4438195005755556, "test_perplexity": 30.000993693329743}, {"epoch": 120, "train_loss": 2.439035774948441, "test_perplexity": 30.190070474975546}, {"epoch": 121, "train_loss": 2.432830745093176, "test_perplexity": 30.03075593518564}, {"epoch": 122, "train_loss": 2.427312305597501, "test_perplexity": 30.186940867246797}, {"epoch": 123, "train_loss": 2.4217480972548513, "test_perplexity": 30.529394194183475}, {"epoch": 124, "train_loss": 2.4155918841607105, "test_perplexity": 30.523430060850817}, {"epoch": 125, "train_loss": 2.409657701710674, "test_perplexity": 30.622319853706482}, {"epoch": 126, "train_loss": 2.4036325171729116, "test_perplexity": 30.785962985801916}, {"epoch": 127, "train_loss": 2.398041352211872, "test_perplexity": 30.764640028001413}], "after_train_perplexity": 30.764640028001413}